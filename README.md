Training a BERT model with a dataset made from the text corpora developed by collecting research papers published in public oncology journals from last 10 years. This BERT based Bio Medical Model (BMLM) is among the very few NLP models that have been trained from scratch using raw text from the Radiation Oncology domain. Another pre-existing model [BioBERT](https://huggingface.co/dmis-lab/biobert-v1.1) is trained on the same dataset so BMLM can be compared with it. The models were trained as described in [this huggingface notebook](https://github.com/huggingface/blog/blob/master/notebooks/01_how_to_train.ipynb) with Masked Language Modeling as the downstream task.
